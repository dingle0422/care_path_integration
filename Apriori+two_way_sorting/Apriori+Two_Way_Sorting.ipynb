{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apriori\n",
    "def find_itemset(data, min_support): #配合数据清理用\n",
    "    '''利用Apriori方法，从原生数据库的消费记录中，挖掘出高频项目组合的参照表\n",
    "    data：原生数据集，如初诊数据\n",
    "    min_support: 筛选阈值\n",
    "    '''\n",
    "    from collections import defaultdict\n",
    "    from itertools import combinations \n",
    "\n",
    "    dict_itemset = {} #the final output, recording the itemsets titled by length of set\n",
    "    data_itemset = data.groupby(['关联键','证件号（id）','date'])['消费项目'].unique().reset_index(drop = False)\n",
    "    print(\"一共存在{}个初/复诊消费组合记录\".format(len(data_itemset)))\n",
    "    \n",
    "    itemset = [set(i) for i in list(data_itemset['消费项目'])]\n",
    "    \n",
    "    #create c1 as units for longer subsets\n",
    "    #all the longer subsets are constructed from the key of c1\n",
    "    uni_items = list(data['消费项目'].unique())\n",
    "    all_items = list(data['消费项目'])\n",
    "    c1 = {}\n",
    "    for i in uni_items:\n",
    "        if i in all_items:\n",
    "            c1[i] = all_items.count(i) \n",
    "    \n",
    "    forlower = pd.DataFrame(np.array(list(c1.values()))).describe()\n",
    "    print(\"单一项目作为itemset时，所有support的分布为{}，\\n可作为取min_support参考\".format(forlower))\n",
    "    \n",
    "    c1 = {key:value for key,value in c1.items() if value >= min_support} #we filter out all the items that is lower than min_support, and this c1 will be the units/blocks to create longer itemsets.\n",
    "    #we also add c1 to our final output for a complete xlsx file.   \n",
    "    formatedc1 = defaultdict(int)\n",
    "    for key,value in c1.items():\n",
    "        formatedc1[\"{'\"+ key +\"'}\"] = value\n",
    "    dict_itemset[1] = formatedc1\n",
    "    \n",
    "    #here, we initialize our c1 and f1 used for compare, and other parameter needed in loop\n",
    "    c1_itemset = list(c1.keys())\n",
    "    f1 = [set([i]) for i in c1_itemset] # used for check if the subset is exist in the former table\n",
    "    len_of_count = None\n",
    "    rounds = 0 #record how many times we run the while loop\n",
    "    \n",
    "    \n",
    "    while len_of_count != 0:\n",
    "        c2_itemset = [set(i) for i in list(combinations(c1_itemset,rounds + 2))] # we generate k+n subset by c1_itemset as unit\n",
    "        #step1: record the k length subsets and their count from global itemset\n",
    "        counts = defaultdict(int)\n",
    "        for i in c2_itemset:\n",
    "            for o in itemset:\n",
    "                if i.issubset(o):\n",
    "                    counts[\"{}\".format(i)] += 1\n",
    "            if counts[\"{}\".format(i)] < min_support: #filter out the itemset whose count is lower than threshold\n",
    "                del counts[\"{}\".format(i)]\n",
    "\n",
    "        #step2: check if len_of_count >0 and the (k-1) length subsets is in the former k length subset\n",
    "        len_of_count = len(counts)\n",
    "        if len_of_count > 0:\n",
    "            key_of_count = list(counts.keys())\n",
    "            len_to_sub = len(key_of_count[0].split(\",\")) - 1\n",
    "            for nset in key_of_count:\n",
    "                sub = nset.lstrip(\"{'\").rstrip(\"'}\").split(\"', '\")\n",
    "                list_of_subset = [set(i) for i in list(combinations(sub, len_to_sub))]\n",
    "                if all((i in f1) for i in list_of_subset) == False: # if the (k-1) length subsets of k length subset are not all in f1 which is the former (k-1) subset. we remove it.\n",
    "                    del counts[nset]\n",
    "\n",
    "            rounds += 1\n",
    "            f1 = c2_itemset.copy()\n",
    "            dict_itemset[rounds+1] = counts\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return dict_itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_way_sorting\n",
    "def two_way(data): #配合set_to_cell用\n",
    "    '''基于先比cardinality再比frequency的原则，进行贪心排序\n",
    "    data: 原生消费项目字符串'''\n",
    "    from itertools import combinations #该module用来将数组或列表进行组合配对\n",
    "    \n",
    "    item_dic = {}\n",
    "    itemset = set(data.split(\",\")) #将消费组合分裂后放入set\n",
    "    output = []\n",
    "    \n",
    "    if itemset in item_keys:   #如果该消费组合自己本身就在item_key里，我们就可以直接默认他为一个item-set，因为我们以cardinality为第一优先级\n",
    "        pos1 = item_keys.index(itemset) #找到该组合再item——keys中的序列号\n",
    "        #set_freq = list(item_values)[pos1]\n",
    "        output.append(itemset)\n",
    "        return output #导出list of sets\n",
    "    elif len(itemset) == 2: #如果消费的总项目只有2个，而且它们的组合不在组合的对照表中，那么我们逐个进行识别，看他们是否伪单独得高频项目，是则纳入，不是则删除\n",
    "        if {list(itemset)[0]} in item_keys:\n",
    "            output.append({list(itemset)[0]})\n",
    "        if {list(itemset)[1]} in item_keys:\n",
    "            output.append({list(itemset)[1]})\n",
    "        return output\n",
    "    \n",
    "    elif len(itemset) == 1: #如果总项目只有1个，且它不在对照表中出现，说明是低频项目，直接删除\n",
    "        return output\n",
    "    \n",
    "    #总项目两个以上，并且它们的全项目组合不在对照表中，我们进行组合，然后查找对照表\n",
    "    else: #如果不符合以上3种情况（长度小于等于2，且自己本身不是高频组合），我们再对消费组合进行配对组合（比如，5个项目的消费组合，我们就以4、3、2、1为subset的size进行配对，再去item_keys里查找是否存在这样的组合）\n",
    "        for x in range(len(itemset)-1): #不让combinations的组合size取到0\n",
    "            bags = list(combinations(itemset, len(itemset)-1-x))\n",
    "\n",
    "            #检查分配出来的组合是否存在于组合集中\n",
    "            quick_out = [] #单个项目且不在对照表里\n",
    "            for p in bags: \n",
    "                if set(p) in item_keys:\n",
    "                    pos2 = item_keys.index(set(p)) #同上，找到index，并找value，存入字典\n",
    "                    item_dic[\"{}\".format(set(p))] = list(item_values)[pos2]\n",
    "                elif len(set(p)) == 1: #单个项目且不在对照表里，需要被拿出来，在return时直接与成包的消费项目组合输出\n",
    "                    quick_out.append(set(p))\n",
    "                    \n",
    "        if (len(item_dic) == 0) and (len(quick_out) > 0): # 如果所有组合或者单个消费都不在对照表中出现，那么消费项目直接单独成包输出\n",
    "            return quick_out\n",
    "        #在item_dic中保存的是在对照表里存在的该消费项目的消费组合，cardinality不一，出现的frequency不一样，所以我们现在进行比较two-way sorting：  \n",
    "        ###优先比较cardinality\n",
    "        cardi_list = []\n",
    "        for i in item_dic.keys():\n",
    "            cardi_list.append(len(i.split(\",\")))\n",
    "            \n",
    "        if (len(set(cardi_list)) == 1) and (set(cardi_list) == {1}):\n",
    "            later_out = [{i.lstrip(\"{'\").rstrip(\"'}\")} for i in list(item_dic.keys())]\n",
    "            return later_out + quick_out #长度为1在对照表的包 + 长度为1单不在对照表中的包 \n",
    "\n",
    "        else:    \n",
    "            #得出最大cardinality在list中的位置  \n",
    "            num_of_max = cardi_list.count(max(cardi_list))\n",
    "            list_of_idx = []\n",
    "            while num_of_max > 0:\n",
    "                idx = cardi_list.index(max(cardi_list))\n",
    "                list_of_idx.append(idx) \n",
    "                cardi_list[idx] = 0 #把最大cardi换成0，以便后面比更低的\n",
    "                num_of_max -= 1\n",
    "            ###得出最大cardi的组中，freq最高的item set  \n",
    "            val = 0 #initalize value number\n",
    "            for o in list_of_idx:\n",
    "                if list(item_dic.values())[o] > val:\n",
    "                    val = list(item_dic.values())[o]\n",
    "                    max_freq = o\n",
    "        \n",
    "            ##得出了cardi最大并且freq最大的item-set，我们将该item-set作为其中一个super event\n",
    "            superevent1 = set((list(item_dic.keys())[max_freq]).lstrip(\"{'\").rstrip(\"'}\").split(\"', '\"))\n",
    "            output.append(superevent1)\n",
    "            itemset -= superevent1\n",
    "            \n",
    "            return output, \",\".join(list(itemset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_to_cell(dat):#配合two_way用\n",
    "    '''基于two way算法，对每个原生消费字符串进行多轮切割直至所有项目都被切割完成\n",
    "    dat： 原生消费项目字符串'''\n",
    "    tocell = []\n",
    "    \n",
    "    ###看item_dic中是否存在组合，可以覆盖到剩下的消费项目：\n",
    "    check = two_way(dat)    \n",
    "    if (all([(type(e) == set) for e in check])) or (len(check) == 0): #如果list里面全部是set组成的,或者list里根本没有高频组合。说明第一次循环就完成了打包。直接导出\n",
    "        tocell += check\n",
    "        return tocell\n",
    "    \n",
    "    #进入多次分包循环\n",
    "    else:\n",
    "        tocell += check[0]\n",
    "        while (len(check) != 1) and (type(check[1]) == str): #如果结果当中不是单一的list of sets，说明还有剩余的itemset子集需要进行打包处理\n",
    "            round2 = two_way(check[1]) #将剩下部分按two-way的算法再进行分包 #[{“开髓引流术”}]\n",
    "\n",
    "            if type(round2) == list:  \n",
    "                tocell += round2 #分包后得出的第二轮的item set也加入输出的结果中   \n",
    "                check = []\n",
    "                break\n",
    "            elif type(round2) == tuple:\n",
    "                tocell += round2[0]\n",
    "                forcheck = round2[1]\n",
    "                check = two_way(forcheck)\n",
    "                if len(check) == 0:\n",
    "                    break\n",
    "\n",
    "\n",
    "        tocell += check #将最后剩下的单输出放入tocell。完成全部分包步骤\n",
    "\n",
    "    return tocell\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
